{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "039af8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracción global completada.\n",
      "- FULL seguras     : C:\\Users\\hered\\Desktop\\TFM\\TFM\\TFM2\\gt_imc_auto_confident_full.csv\n",
      "- FULL dudosas     : C:\\Users\\hered\\Desktop\\TFM\\TFM\\TFM2\\gt_imc_auto_doubtful_full.csv\n",
      "- FULL descartadas : C:\\Users\\hered\\Desktop\\TFM\\TFM\\TFM2\\gt_imc_auto_discarded_full.csv\n",
      "\n",
      "✅ Muestreo de alta confianza:\n",
      "- Muestra notas    : C:\\Users\\hered\\Desktop\\TFM\\TFM\\TFM2\\sample_notes_imc.csv\n",
      "- Muestra JSONL    : C:\\Users\\hered\\Desktop\\TFM\\TFM\\TFM2\\sample_notes_imc.jsonl\n",
      "- GT FINAL (sample): C:\\Users\\hered\\Desktop\\TFM\\TFM\\TFM2\\gt_imc_final.csv\n",
      "- Seguras (sample) : C:\\Users\\hered\\Desktop\\TFM\\TFM\\TFM2\\gt_imc_confident_sample.csv\n",
      "\n",
      "Resumen (FULL):\n",
      "  Seguras   : 3712\n",
      "  Dudosas   : 6308\n",
      "  Descartes : 157014\n",
      "\n",
      "Resumen (sample):\n",
      "  Tamaño sample seguro: 50 (seed=42)\n"
     ]
    }
   ],
   "source": [
    "# Celda 0 — Extracción global (regex) + muestreo de alta confianza + GT final para IMC\n",
    "# - Recorre TODO PMC-Patients.csv\n",
    "# - Clasifica: alta confianza / dudosos / descartados\n",
    "# - Toma un sample (50) SOLO de alta confianza (seed=42)\n",
    "# - Genera:\n",
    "#     gt_imc_auto_confident_full.csv    (todas las filas seguras de TODO el dataset, con evidencias)\n",
    "#     gt_imc_auto_doubtful_full.csv     (todas las dudosas)\n",
    "#     gt_imc_auto_discarded_full.csv    (todas las descartadas)\n",
    "#     sample_notes_imc.csv              (notas SOLO del sample seguro)\n",
    "#     sample_notes_imc.jsonl            (lo mismo en JSONL)\n",
    "#     gt_imc_final.csv                  (GT limpio SOLO del sample seguro)\n",
    "#     gt_imc_confident_sample.csv       (seguras del sample con evidencias)\n",
    "\n",
    "import re, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- Rutas y parámetros ----------\n",
    "DATA_CSV   = r\"C:\\Users\\hered\\Desktop\\TFM\\TFM\\data\\PMC-Patients.csv\"\n",
    "OUTPUT_DIR = Path(r\"C:\\Users\\hered\\Desktop\\TFM\\TFM\\TFM2\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAMPLE_SIZE = 50\n",
    "SEED = 42\n",
    "MAX_CHAR_DISTANCE = 300  # cercanía entre altura y peso para considerarlo consistente\n",
    "\n",
    "# Salidas \"FULL\" (todo el dataset)\n",
    "CONF_FULL = OUTPUT_DIR / \"gt_imc_auto_confident_full.csv\"\n",
    "DOUBT_FULL = OUTPUT_DIR / \"gt_imc_auto_doubtful_full.csv\"\n",
    "DROP_FULL = OUTPUT_DIR / \"gt_imc_auto_discarded_full.csv\"\n",
    "\n",
    "# Salidas del SAMPLE seguro\n",
    "SAMPLE_NOTES_CSV   = OUTPUT_DIR / \"sample_notes_imc.csv\"\n",
    "SAMPLE_NOTES_JSONL = OUTPUT_DIR / \"sample_notes_imc.jsonl\"\n",
    "GT_FINAL_CSV       = OUTPUT_DIR / \"gt_imc_final.csv\"\n",
    "CONF_SAMPLE        = OUTPUT_DIR / \"gt_imc_confident_sample.csv\"\n",
    "\n",
    "# ---------- Carga robusta ----------\n",
    "df = pd.read_csv(\n",
    "    DATA_CSV,\n",
    "    dtype={\"patient_id\": str},\n",
    "    encoding=\"utf-8\",\n",
    "    engine=\"python\",\n",
    "    on_bad_lines=\"skip\"\n",
    ")\n",
    "\n",
    "required_cols = {\"patient_id\", \"patient\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Faltan columnas requeridas: {missing}. Columnas disponibles: {list(df.columns)}\")\n",
    "\n",
    "df = (\n",
    "    df[[\"patient_id\", \"patient\"]]\n",
    "    .dropna(subset=[\"patient_id\", \"patient\"])\n",
    "    .assign(patient=lambda x: x[\"patient\"].astype(str).str.replace(\"\\u2009\",\" \").str.replace(\"\\u00A0\",\" \").str.strip())\n",
    "    .query(\"patient.str.len() > 0\", engine=\"python\")\n",
    ")\n",
    "\n",
    "# ---------- Parámetros y patrones ----------\n",
    "# Rangos (adultos)\n",
    "H_MIN, H_MAX = 1.2, 2.2      # metros\n",
    "W_MIN, W_MAX = 30.0, 300.0   # kg\n",
    "BMI_MIN, BMI_MAX = 10.0, 80.0\n",
    "\n",
    "CM_RE   = re.compile(r\"\\b(?P<val>\\d{2,3}(?:\\.\\d+)?)\\s*cm\\b\", re.I)\n",
    "M_RE    = re.compile(r\"\\b(?P<val>\\d(?:\\.\\d{1,3})?)\\s*m\\b\", re.I)\n",
    "FTIN_RE = re.compile(r\"\\b(?P<ft>[4-7])\\s*(?:ft|feet|')\\s*(?P<inch>\\d{1,2})?\\s*(?:in|inches|\\\")?\\b\", re.I)\n",
    "\n",
    "KG_RE   = re.compile(r\"\\b(?P<val>\\d{2,3}(?:\\.\\d+)?)\\s*kg\\b\", re.I)\n",
    "LB_RE   = re.compile(r\"\\b(?P<val>\\d{2,3}(?:\\.\\d+)?)\\s*(?:lb|lbs|pounds?)\\b\", re.I)\n",
    "\n",
    "BMI_RE  = re.compile(r\"\\b(?:bmi|body\\s*mass\\s*index)\\s*[:=]?\\s*(?P<val>\\d{1,2}(?:\\.\\d{1,2})?)\\b\", re.I)\n",
    "\n",
    "LAB_UNITS_RE = re.compile(r\"\\b(mg/dl|µ?mol/?l|g/dl|mmol/?l|ng/ml|pg/ml|u/l|iu/l)\\b\", re.I)\n",
    "BLACKLIST = {\"mass\",\"lesion\",\"tumor\",\"nodule\",\"cyst\",\"defect\",\"stone\",\"specimen\"}\n",
    "\n",
    "def inches_to_m(ft:int, inch:int|None) -> float:\n",
    "    total = ft*12 + (inch or 0)\n",
    "    return total * 0.0254\n",
    "\n",
    "def plausible_height(m: float|None) -> bool:\n",
    "    return m is not None and H_MIN <= m <= H_MAX\n",
    "\n",
    "def plausible_weight(kg: float|None) -> bool:\n",
    "    return kg is not None and W_MIN <= kg <= W_MAX\n",
    "\n",
    "def plausible_bmi(b: float|None) -> bool:\n",
    "    return b is not None and BMI_MIN <= b <= BMI_MAX\n",
    "\n",
    "def has_blacklist(snippet: str) -> bool:\n",
    "    s = snippet.lower()\n",
    "    return any(tok in s for tok in BLACKLIST)\n",
    "\n",
    "def extract_heights(text: str):\n",
    "    res = []\n",
    "    for m in M_RE.finditer(text):\n",
    "        try:\n",
    "            val = float(m.group(\"val\"))\n",
    "            if plausible_height(val):\n",
    "                res.append((\"m\", val, m.start(), m.end()))\n",
    "        except: pass\n",
    "    for m in CM_RE.finditer(text):\n",
    "        try:\n",
    "            cm = float(m.group(\"val\"))\n",
    "            val = cm/100.0\n",
    "            if plausible_height(val):\n",
    "                res.append((\"cm\", val, m.start(), m.end()))\n",
    "        except: pass\n",
    "    for m in FTIN_RE.finditer(text):\n",
    "        try:\n",
    "            ft = int(m.group(\"ft\"))\n",
    "            inch = m.group(\"inch\")\n",
    "            inch = int(inch) if inch is not None else 0\n",
    "            val = round(inches_to_m(ft, inch), 3)\n",
    "            if plausible_height(val):\n",
    "                res.append((\"ftin\", val, m.start(), m.end()))\n",
    "        except: pass\n",
    "    return res\n",
    "\n",
    "def extract_weights(text: str):\n",
    "    res = []\n",
    "    for m in KG_RE.finditer(text):\n",
    "        try:\n",
    "            kg = float(m.group(\"val\"))\n",
    "            if plausible_weight(kg):\n",
    "                res.append((\"kg\", kg, m.start(), m.end()))\n",
    "        except: pass\n",
    "    for m in LB_RE.finditer(text):\n",
    "        try:\n",
    "            lb = float(m.group(\"val\"))\n",
    "            kg = round(lb * 0.45359237, 1)\n",
    "            if plausible_weight(kg):\n",
    "                res.append((\"lb\", kg, m.start(), m.end()))\n",
    "        except: pass\n",
    "    return res\n",
    "\n",
    "def extract_bmis(text: str):\n",
    "    res = []\n",
    "    for m in BMI_RE.finditer(text):\n",
    "        try:\n",
    "            val = float(m.group(\"val\"))\n",
    "            if plausible_bmi(val):\n",
    "                win = text[max(0,m.start()-15):m.end()+15]\n",
    "                if not LAB_UNITS_RE.search(win):\n",
    "                    res.append((val, m.start(), m.end()))\n",
    "        except: pass\n",
    "    return res\n",
    "\n",
    "def nearest_pair(heights, weights):\n",
    "    best = None\n",
    "    best_dist = 1e12\n",
    "    for h in heights:\n",
    "        for w in weights:\n",
    "            dist = min(abs(h[2]-w[2]), abs(h[3]-w[2]), abs(h[2]-w[3]), abs(h[3]-w[3]))\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best = (h, w, best_dist)\n",
    "    return best\n",
    "\n",
    "def same_paragraph(text, i, j):\n",
    "    a, b = sorted([i, j])\n",
    "    return text[a:b].count(\"\\n\") <= 1\n",
    "\n",
    "def compute_bmi(h, w):\n",
    "    try:\n",
    "        return round(w/(h*h), 2)\n",
    "    except: return None\n",
    "\n",
    "# ---------- Extracción sobre TODO el dataset ----------\n",
    "conf_rows, doubt_rows, drop_rows = [], [], []\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    pid = r[\"patient_id\"]\n",
    "    text = r[\"patient\"]\n",
    "\n",
    "    Hs = extract_heights(text)\n",
    "    Ws = extract_weights(text)\n",
    "    Bs = extract_bmis(text)\n",
    "\n",
    "    # Filtrar por blacklist en ventana local\n",
    "    Hs2 = []\n",
    "    for tag, val, s, e in Hs:\n",
    "        snip = text[max(0, s-40):e+40]\n",
    "        if not has_blacklist(snip):\n",
    "            Hs2.append((tag, val, s, e))\n",
    "    Ws2 = []\n",
    "    for tag, val, s, e in Ws:\n",
    "        snip = text[max(0, s-40):e+40]\n",
    "        if not has_blacklist(snip):\n",
    "            Ws2.append((tag, val, s, e))\n",
    "\n",
    "    if not Hs2 and not Ws2 and not Bs:\n",
    "        drop_rows.append({\"patient_id\": pid, \"reason\": \"no_matches\", \"text_preview\": text[:200]})\n",
    "        continue\n",
    "\n",
    "    if Hs2 and Ws2:\n",
    "        h, w, dist = nearest_pair(Hs2, Ws2)\n",
    "        h_m, w_kg = h[1], w[1]\n",
    "        bmi_calc = compute_bmi(h_m, w_kg)\n",
    "\n",
    "        bmi_explicit = Bs[0][0] if Bs else None\n",
    "        explicit_ok = (bmi_explicit is None) or (bmi_calc is not None and abs(bmi_calc - bmi_explicit) <= 0.5)\n",
    "        close_enough = (dist <= MAX_CHAR_DISTANCE) or same_paragraph(text, h[2], w[2])\n",
    "\n",
    "        if plausible_height(h_m) and plausible_weight(w_kg) and close_enough and explicit_ok and plausible_bmi(bmi_calc):\n",
    "            conf_rows.append({\n",
    "                \"patient_id\": pid,\n",
    "                \"height_m_true\": round(h_m, 3),\n",
    "                \"weight_kg_true\": round(w_kg, 1),\n",
    "                \"BMI_true\": bmi_calc,\n",
    "                \"bmi_explicit_in_note\": bool(Bs),\n",
    "                \"evidence_height\": text[max(0, h[2]-60):h[3]+60],\n",
    "                \"evidence_weight\": text[max(0, w[2]-60):w[3]+60],\n",
    "                \"evidence_bmi\": (text[max(0, Bs[0][1]-60):Bs[0][2]+60] if Bs else None),\n",
    "                \"char_distance_hw\": int(dist),\n",
    "                \"patient\": text  # guardamos la nota completa para poder muestrear y exportar\n",
    "            })\n",
    "        else:\n",
    "            doubt_rows.append({\n",
    "                \"patient_id\": pid,\n",
    "                \"height_m_candidate\": round(h_m,3),\n",
    "                \"weight_kg_candidate\": round(w_kg,1),\n",
    "                \"BMI_calc\": bmi_calc,\n",
    "                \"BMI_explicit\": bmi_explicit,\n",
    "                \"close_enough\": close_enough,\n",
    "                \"explicit_ok\": explicit_ok,\n",
    "                \"char_distance_hw\": int(dist),\n",
    "                \"text_preview\": text[:300]\n",
    "            })\n",
    "    else:\n",
    "        bmi_explicit = Bs[0][0] if Bs else None\n",
    "        doubt_rows.append({\n",
    "            \"patient_id\": pid,\n",
    "            \"height_m_candidate\": (round(Hs2[0][1],3) if Hs2 else None),\n",
    "            \"weight_kg_candidate\": (round(Ws2[0][1],1) if Ws2 else None),\n",
    "            \"BMI_calc\": None,\n",
    "            \"BMI_explicit\": bmi_explicit,\n",
    "            \"close_enough\": False,\n",
    "            \"explicit_ok\": False,\n",
    "            \"char_distance_hw\": None,\n",
    "            \"text_preview\": text[:300]\n",
    "        })\n",
    "\n",
    "# ---------- Guardar FULL ----------\n",
    "pd.DataFrame(conf_rows).to_csv(CONF_FULL, index=False, encoding=\"utf-8\")\n",
    "pd.DataFrame(doubt_rows).to_csv(DOUBT_FULL, index=False, encoding=\"utf-8\")\n",
    "pd.DataFrame(drop_rows).to_csv(DROP_FULL, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# ---------- Muestreo SOLO de alta confianza ----------\n",
    "conf_df = pd.DataFrame(conf_rows)\n",
    "if len(conf_df) == 0:\n",
    "    raise RuntimeError(\"No se han encontrado filas de alta confianza. Revisa las reglas/umbrales.\")\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "take = min(SAMPLE_SIZE, len(conf_df))\n",
    "sample_idx = rng.choice(conf_df.index, size=take, replace=False)\n",
    "conf_sample = conf_df.loc[sample_idx].reset_index(drop=True)\n",
    "\n",
    "# Notas del sample (para inferencia posterior)\n",
    "notes_sample = conf_sample[[\"patient_id\",\"patient\"]].copy()\n",
    "notes_sample.to_csv(SAMPLE_NOTES_CSV, index=False)\n",
    "with open(SAMPLE_NOTES_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in notes_sample.iterrows():\n",
    "        f.write(json.dumps({\"patient_id\": row[\"patient_id\"], \"patient\": row[\"patient\"]}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# GT limpio SOLO del sample\n",
    "gt_final = conf_sample[[\"patient_id\",\"height_m_true\",\"weight_kg_true\",\"BMI_true\",\"bmi_explicit_in_note\"]].copy()\n",
    "gt_final.to_csv(GT_FINAL_CSV, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# También guardamos las seguras del sample con evidencias\n",
    "conf_sample.to_csv(CONF_SAMPLE, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# ---------- Informe ----------\n",
    "print(\"✅ Extracción global completada.\")\n",
    "print(f\"- FULL seguras     : {CONF_FULL}\")\n",
    "print(f\"- FULL dudosas     : {DOUBT_FULL}\")\n",
    "print(f\"- FULL descartadas : {DROP_FULL}\")\n",
    "\n",
    "print(\"\\n✅ Muestreo de alta confianza:\")\n",
    "print(f\"- Muestra notas    : {SAMPLE_NOTES_CSV}\")\n",
    "print(f\"- Muestra JSONL    : {SAMPLE_NOTES_JSONL}\")\n",
    "print(f\"- GT FINAL (sample): {GT_FINAL_CSV}\")\n",
    "print(f\"- Seguras (sample) : {CONF_SAMPLE}\")\n",
    "\n",
    "print(\"\\nResumen (FULL):\")\n",
    "print(f\"  Seguras   : {len(conf_rows)}\")\n",
    "print(f\"  Dudosas   : {len(doubt_rows)}\")\n",
    "print(f\"  Descartes : {len(drop_rows)}\")\n",
    "\n",
    "print(\"\\nResumen (sample):\")\n",
    "print(f\"  Tamaño sample seguro: {len(conf_sample)} (seed={SEED})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
